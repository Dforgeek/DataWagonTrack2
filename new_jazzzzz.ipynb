{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нью рок нью джаз\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"train\"\n",
    "\n",
    "wag_prob = pd.read_parquet(path_train + \"/wagons_probeg_ownersip.parquet\").convert_dtypes()\n",
    "wag_param = pd.read_parquet(path_train + \"/wag_params.parquet\").convert_dtypes()\n",
    "target = pd.read_csv(path_train +'/target/y_train.csv').convert_dtypes()\n",
    "to_predict = pd.read_csv(path_train +'/target/y_predict.csv').convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = target[target[\"month\"] == \"2022-12-01\"].drop(\"month\", axis=1)\n",
    "train = wag_prob[wag_prob[\"repdate\"] < \"2022-12-01\"]\n",
    "\n",
    "features = train.groupby(\"wagnum\").agg(\n",
    "    {\n",
    "        \"ost_prob\": [\"mean\", \"last\", \"max\"],\n",
    "        \"manage_type\": \"last\",\n",
    "        \"rod_id\": \"last\",\n",
    "        \"reestr_state\": \"last\",\n",
    "    }\n",
    ")\n",
    "features.columns = [\"_\".join(col).strip() for col in features.columns.values]\n",
    "features = features.reset_index()\n",
    "\n",
    "m_train = wag_param.drop(\n",
    "    [\"model\", \"tipvozd\", \"date_build\", \"srok_sl\", \"date_iskl\"], axis=1\n",
    ")\n",
    "\n",
    "merged = features.merge(m_train, on=\"wagnum\", how=\"inner\")\n",
    "merged = train_target.merge(merged, on=\"wagnum\", how=\"left\")\n",
    "\n",
    "\n",
    "column_names = merged.columns\n",
    "\n",
    "merged = imputer.fit_transform(merged)\n",
    "\n",
    "merged = pd.DataFrame(merged, columns=column_names)\n",
    "\n",
    "X_train = merged.drop([\"target_day\", \"wagnum\"], axis=1)\n",
    "y_name = \"target_month\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train.drop(y_name, axis=1), X_train[y_name])\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train.drop(y_name, axis=1), X_train[y_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = target[target[\"month\"] == \"2023-01-01\"].drop(\"month\", axis=1)\n",
    "test = wag_prob[wag_prob[\"repdate\"] < \"2023-01-01\"]\n",
    "\n",
    "test_features = test.groupby(\"wagnum\").agg(\n",
    "    {\n",
    "        \"ost_prob\": [\"mean\", \"last\", \"max\"],\n",
    "        \"manage_type\": \"last\",\n",
    "        \"rod_id\": \"last\",\n",
    "        \"reestr_state\": \"last\",\n",
    "    }\n",
    ")\n",
    "test_features.columns = [\"_\".join(col).strip() for col in test_features.columns.values]\n",
    "test_features = test_features.reset_index()\n",
    "\n",
    "m_test = wag_param.drop(\n",
    "    [\"model\", \"tipvozd\", \"date_build\", \"srok_sl\", \"date_iskl\"], axis=1\n",
    ")\n",
    "\n",
    "merged = test_features.merge(m_test, on=\"wagnum\", how=\"inner\")\n",
    "merged = test_target.merge(merged, on=\"wagnum\", how=\"left\")\n",
    "column_names = merged.columns\n",
    "merged = imputer.fit_transform(merged)\n",
    "merged = pd.DataFrame(merged, columns=column_names)\n",
    "\n",
    "X_test = merged.drop([\"target_day\", \"wagnum\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.027972027972027975\n",
      "Random Forest F1 Score: 0.48882374496152436\n"
     ]
    }
   ],
   "source": [
    "y_pred_logreg = logreg.predict(X_test.drop(y_name, axis=1))\n",
    "y_pred_rf = rf.predict(X_test.drop(y_name, axis=1))\n",
    "\n",
    "f1_logreg = f1_score(X_test[y_name], y_pred_logreg)\n",
    "print(f\"Logistic Regression F1 Score: {f1_logreg}\")\n",
    "\n",
    "f1_rf = f1_score(X_test[y_name], y_pred_rf)\n",
    "print(f\"Random Forest F1 Score: {f1_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"17.0.7\" 2023-04-18; OpenJDK Runtime Environment (build 17.0.7+7-Ubuntu-0ubuntu122.04.2); OpenJDK 64-Bit Server VM (build 17.0.7+7-Ubuntu-0ubuntu122.04.2, mixed mode, sharing)\n",
      "  Starting server from /home/linreg/.local/lib/python3.10/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpsvfwmq1w\n",
      "  JVM stdout: /tmp/tmpsvfwmq1w/h2o_linreg_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpsvfwmq1w/h2o_linreg_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Moscow</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.42.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 19 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_linreg_csnson</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.865 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.6 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         01 secs\n",
       "H2O_cluster_timezone:       Europe/Moscow\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.42.0.3\n",
       "H2O_cluster_version_age:    2 months and 19 days\n",
       "H2O_cluster_name:           H2O_from_python_linreg_csnson\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.865 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.6 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "11:02:24.942: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "██\n",
      "11:02:36.718: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "\n",
      "11:02:38.781: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "██\n",
      "11:02:48.435: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "█\n",
      "11:02:53.921: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "██\n",
      "11:03:08.755: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "█\n",
      "11:03:14.363: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "█\n",
      "11:03:20.15: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "█\n",
      "11:03:26.581: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "█\n",
      "11:03:29.68: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "███\n",
      "11:03:44.765: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "\n",
      "11:03:49.809: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "███████████████\n",
      "11:04:29.143: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "██████\n",
      "11:04:31.411: _response param, We have detected that your response column has only 2 unique values (0/1). If you wish to train a binary model instead of a regression model, convert your target column to categorical before training.\n",
      "\n",
      "████████████████████████████| (done) 100%\n",
      "model_id                                                     rmse        mse        mae     rmsle    mean_residual_deviance\n",
      "StackedEnsemble_AllModels_1_AutoML_1_20231111_110224     0.166233  0.0276335  0.0561972  0.116286                 0.0276335\n",
      "StackedEnsemble_BestOfFamily_1_AutoML_1_20231111_110224  0.166542  0.0277364  0.0569228  0.116631                 0.0277364\n",
      "GBM_1_AutoML_1_20231111_110224                           0.166562  0.0277429  0.0563294  0.11668                  0.0277429\n",
      "GBM_5_AutoML_1_20231111_110224                           0.167056  0.0279077  0.0554025  0.116771                 0.0279077\n",
      "GBM_2_AutoML_1_20231111_110224                           0.167454  0.0280408  0.0558532  0.117229                 0.0280408\n",
      "GBM_grid_1_AutoML_1_20231111_110224_model_1              0.167703  0.0281243  0.0561699  0.117323                 0.0281243\n",
      "GBM_3_AutoML_1_20231111_110224                           0.167816  0.0281622  0.0560168  0.117289                 0.0281622\n",
      "GBM_4_AutoML_1_20231111_110224                           0.16929   0.0286592  0.0561254  0.118652                 0.0286592\n",
      "XGBoost_3_AutoML_1_20231111_110224                       0.170763  0.0291599  0.05578    0.119776                 0.0291599\n",
      "XRT_1_AutoML_1_20231111_110224                           0.171992  0.0295812  0.0613462  0.121638                 0.0295812\n",
      "DRF_1_AutoML_1_20231111_110224                           0.172215  0.0296578  0.0556989  0.121553                 0.0296578\n",
      "DeepLearning_1_AutoML_1_20231111_110224                  0.177126  0.0313736  0.067251   0.123855                 0.0313736\n",
      "XGBoost_grid_1_AutoML_1_20231111_110224_model_2          0.182045  0.0331404  0.0579553  0.12886                  0.0331404\n",
      "XGBoost_1_AutoML_1_20231111_110224                       0.182582  0.0333362  0.0625871  0.130439                 0.0333362\n",
      "XGBoost_2_AutoML_1_20231111_110224                       0.183314  0.0336042  0.0603857  0.130404                 0.0336042\n",
      "XGBoost_grid_1_AutoML_1_20231111_110224_model_1          0.191711  0.0367533  0.0614066  0.136168                 0.0367533\n",
      "GLM_1_AutoML_1_20231111_110224                           0.198855  0.0395434  0.0972262  0.140082                 0.0395434\n",
      "[17 rows x 6 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "import pandas as pd\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "h2o.init()\n",
    "\n",
    "train = h2o.H2OFrame(X_train)\n",
    "test = h2o.H2OFrame(X_test)\n",
    "\n",
    "x = train.columns\n",
    "x.remove(y_name)\n",
    "\n",
    "aml = H2OAutoML(max_models=15, seed=42)\n",
    "aml.train(x=x, y=y_name, training_frame=train)\n",
    "\n",
    "lb = aml.leaderboard\n",
    "print(lb.head(rows=lb.nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "F1: 0.5753688261706221\n"
     ]
    }
   ],
   "source": [
    "y_pred = aml.predict(test).as_data_frame().squeeze()\n",
    "y_pred_labels = (y_pred > 0.4).astype(int)\n",
    "result = f1_score(X_test[y_name], y_pred_labels)\n",
    "print(f\"F1: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2o.save_model(aml.leader, path=f\"saved_models/h20_{result}\")\n",
    "h2o.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Feature  Importance\n",
      "9          cnsi_volumek    0.005600\n",
      "13       cnsi_probeg_kr    0.002640\n",
      "12       cnsi_probeg_dr    0.001805\n",
      "10                 tara    0.001550\n",
      "7                  gruz    0.001122\n",
      "8    cnsi_gruz_capacity    0.001122\n",
      "14                kuzov    0.000475\n",
      "17              tippogl    0.000218\n",
      "1         ost_prob_last    0.000077\n",
      "3           rod_id_last    0.000074\n",
      "6                rod_id    0.000074\n",
      "15               telega    0.000035\n",
      "19            ownertype    0.000020\n",
      "16               tormoz    0.000011\n",
      "0         ost_prob_mean    0.000009\n",
      "18             norma_km    0.000007\n",
      "2      manage_type_last    0.000005\n",
      "4     reestr_state_last    0.000002\n",
      "11          zavod_build    0.000002\n",
      "5   ownership_type_last    0.000000\n"
     ]
    }
   ],
   "source": [
    "feature_importance = logreg.coef_\n",
    "\n",
    "avg_feature_importance = np.mean(np.abs(feature_importance), axis=0)\n",
    "\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    {\"Feature\": X_train.columns, \"Importance\": avg_feature_importance}\n",
    ")\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(\n",
    "    by=\"Importance\", ascending=False\n",
    ")\n",
    "\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rf.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    {\"Feature\": X_train.columns, \"Importance\": feature_importance}\n",
    ")\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(\n",
    "    by=\"Importance\", ascending=False\n",
    ")\n",
    "\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
