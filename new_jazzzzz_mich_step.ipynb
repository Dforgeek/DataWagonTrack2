{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T02:49:39.828950200Z",
     "start_time": "2023-11-12T02:49:39.586808900Z"
    }
   },
   "outputs": [],
   "source": [
    "# нью рок нью джаз\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T02:49:40.234950Z",
     "start_time": "2023-11-12T02:49:39.593810300Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T02:49:44.440092Z",
     "start_time": "2023-11-12T02:49:39.610809600Z"
    }
   },
   "outputs": [],
   "source": [
    "path_train = \"train\"\n",
    "\n",
    "wag_prob = pd.read_parquet(path_train + \"/wagons_probeg_ownersip.parquet\").convert_dtypes()\n",
    "target = pd.read_csv(path_train + '/target/y_train.csv').convert_dtypes()\n",
    "to_predict = pd.read_csv(path_train + '/target/y_predict.csv').convert_dtypes()\n",
    "wag_param = pd.read_parquet(path_train + \"/wag_params.parquet\").convert_dtypes()\n",
    "# добавляем kri_izm\n",
    "kri_izm = pd.read_parquet(path_train + '/kti_izm.parquet').convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "        wagnum       month  target_month  target_day\n0        33361  2023-01-01             0           0\n1        33364  2023-01-01             0           0\n2        33366  2023-01-01             0           0\n3        33358  2023-01-01             0           0\n4        33349  2023-01-01             0           0\n...        ...         ...           ...         ...\n203848   25045  2022-12-01             0           0\n203849   27156  2022-12-01             0           0\n203850   21361  2022-12-01             0           0\n203851    8061  2022-12-01             0           0\n203852   33350  2022-12-01             1           0\n\n[203853 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>wagnum</th>\n      <th>month</th>\n      <th>target_month</th>\n      <th>target_day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>33361</td>\n      <td>2023-01-01</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>33364</td>\n      <td>2023-01-01</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33366</td>\n      <td>2023-01-01</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33358</td>\n      <td>2023-01-01</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33349</td>\n      <td>2023-01-01</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>203848</th>\n      <td>25045</td>\n      <td>2022-12-01</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>203849</th>\n      <td>27156</td>\n      <td>2022-12-01</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>203850</th>\n      <td>21361</td>\n      <td>2022-12-01</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>203851</th>\n      <td>8061</td>\n      <td>2022-12-01</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>203852</th>\n      <td>33350</td>\n      <td>2022-12-01</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>203853 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T02:49:44.464093200Z",
     "start_time": "2023-11-12T02:49:44.433093700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "           repdate  wagnum  ost_prob  manage_type  rod_id  reestr_state  \\\n0       2022-08-01   33361      7541            0       1             1   \n1       2022-08-02   33361      7243            0       1             1   \n2       2022-08-03   33361      6990            0       1             1   \n3       2022-08-04   33361      6347            0       1             1   \n4       2022-08-05   33361      6027            0       1             1   \n...            ...     ...       ...          ...     ...           ...   \n9249584 2022-12-20   33350     35062            0       1             0   \n9249585 2022-12-21   33350     35062            0       1             0   \n9249586 2022-12-22   33350     35062            0       1             0   \n9249587 2022-12-23   33350     35062            0       1             0   \n9249588 2022-12-24   33350     35062            0       1             0   \n\n         ownership_type  month  \n0                     0      8  \n1                     0      8  \n2                     0      8  \n3                     0      8  \n4                     0      8  \n...                 ...    ...  \n9249584               0     12  \n9249585               0     12  \n9249586               0     12  \n9249587               0     12  \n9249588               0     12  \n\n[6249857 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>repdate</th>\n      <th>wagnum</th>\n      <th>ost_prob</th>\n      <th>manage_type</th>\n      <th>rod_id</th>\n      <th>reestr_state</th>\n      <th>ownership_type</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-08-01</td>\n      <td>33361</td>\n      <td>7541</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-08-02</td>\n      <td>33361</td>\n      <td>7243</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-08-03</td>\n      <td>33361</td>\n      <td>6990</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-08-04</td>\n      <td>33361</td>\n      <td>6347</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-08-05</td>\n      <td>33361</td>\n      <td>6027</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9249584</th>\n      <td>2022-12-20</td>\n      <td>33350</td>\n      <td>35062</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>9249585</th>\n      <td>2022-12-21</td>\n      <td>33350</td>\n      <td>35062</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>9249586</th>\n      <td>2022-12-22</td>\n      <td>33350</td>\n      <td>35062</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>9249587</th>\n      <td>2022-12-23</td>\n      <td>33350</td>\n      <td>35062</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>9249588</th>\n      <td>2022-12-24</td>\n      <td>33350</td>\n      <td>35062</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n<p>6249857 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wag_prob"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T02:49:44.492091600Z",
     "start_time": "2023-11-12T02:49:44.459093600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train_target = target\n",
    "\n",
    "train = wag_prob\n",
    "\n",
    "\n",
    "path_test = 'test'\n",
    "test_target = pd.read_csv(path_test + '/target/y_test.csv').convert_dtypes().drop(\"month\", axis=1)\n",
    "test = wag_prob\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T02:49:44.603092200Z",
     "start_time": "2023-11-12T02:49:44.475094300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "     repdate  wagnum  ost_prob  manage_type  rod_id  reestr_state  \\\n0 2022-08-01   33361      7541            0       1             1   \n1 2022-08-02   33361      7243            0       1             1   \n2 2022-08-03   33361      6990            0       1             1   \n3 2022-08-04   33361      6347            0       1             1   \n4 2022-08-05   33361      6027            0       1             1   \n\n   ownership_type  month  \n0               0      8  \n1               0      8  \n2               0      8  \n3               0      8  \n4               0      8  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>repdate</th>\n      <th>wagnum</th>\n      <th>ost_prob</th>\n      <th>manage_type</th>\n      <th>rod_id</th>\n      <th>reestr_state</th>\n      <th>ownership_type</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-08-01</td>\n      <td>33361</td>\n      <td>7541</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-08-02</td>\n      <td>33361</td>\n      <td>7243</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-08-03</td>\n      <td>33361</td>\n      <td>6990</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-08-04</td>\n      <td>33361</td>\n      <td>6347</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-08-05</td>\n      <td>33361</td>\n      <td>6027</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T02:49:44.654092800Z",
     "start_time": "2023-11-12T02:49:44.504093400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def get_dislok(path=path_train + \"/dislok_wagons.parquet\"):\n",
    "\n",
    "    dislok_wagons = pd.read_parquet(path).convert_dtypes()\n",
    "    \n",
    "    dis_train = dislok_wagons[dislok_wagons[\"plan_date\"] < \"2023-02-01\"]\n",
    "    february_date = \"2023-02-01\"\n",
    "    base_date = pd.to_datetime(february_date)\n",
    "    days_from_kap_mean = (base_date - dis_train[\"date_kap\"]).dt.days.mean()\n",
    "    days_from_dep_mean = (base_date - dis_train[\"date_dep\"]).dt.days.mean()\n",
    "    \n",
    "    dis_train[\"days_from_kap\"] = (pd.to_datetime(february_date) - dis_train[\"date_kap\"]).dt.days\n",
    "    dis_train[\"days_from_dep\"] = (pd.to_datetime(february_date) - dis_train[\"date_dep\"]).dt.days\n",
    "    \n",
    "    # Fill missing values with mean\n",
    "    dis_train['days_from_kap'] = dis_train['days_from_kap'].fillna(-1)\n",
    "    dis_train['days_from_dep'] = dis_train['days_from_dep'].fillna(-1)\n",
    "    dis_train[\"days_to_date_pl_rem\"] = (base_date - dis_train[\"date_pl_rem\"]).dt.days\n",
    "    \n",
    "    dis_train = dis_train.groupby('wagnum').agg({\n",
    "        'plan_date': ['last'], \n",
    "        'days_from_kap': lambda x: x[x != -1].iloc[0] if (x != -1).any() else days_from_kap_mean,\n",
    "        'days_from_dep': lambda x: x[x != -1].iloc[0] if (x != -1).any() else days_from_dep_mean,\n",
    "        'days_to_date_pl_rem': lambda x: x[x.notnull()].iloc[-1] if x.notnull().any() else None,\n",
    "        'date_pl_rem': lambda x: x[x.notnull()].iloc[-1] if x.notnull().any() else None, # поменять\n",
    "        'distance': 'last',\n",
    "        'isload': 'last',\n",
    "        'ost_prob': 'last'\n",
    "    })\n",
    "    \n",
    "    dis_train.columns = ['plan_date', 'days_from_kap', 'days_from_dep', 'days_to_date_pl_rem',\n",
    "                     'date_pl_rem', 'distance', 'isload', 'ost_prob']\n",
    "    return dis_train['days_to_date_pl_rem']\n",
    "    #return dis_train[['']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T02:49:44.686749100Z",
     "start_time": "2023-11-12T02:49:44.524093500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def prepare_data(group_data, wag_param, target=None, columns_to_drop=None,\n",
    "                 columns_to_drop_wag_param=None, columns_to_log=None,\n",
    "                 imputer_strategy='most_frequent', without_wagnum=True):\n",
    "    # Group and aggregate the data\n",
    "    if columns_to_drop_wag_param is None:\n",
    "        columns_to_drop_wag_param = [\"model\", \"tipvozd\", \"date_build\", \"srok_sl\", \"date_iskl\"]\n",
    "\n",
    "    features = group_data.groupby(\"wagnum\").agg(\n",
    "        {\n",
    "            \"ost_prob\": [\"mean\", \"last\", \"max\", 'std', 'min'],\n",
    "            \"manage_type\": \"last\",\n",
    "            \"rod_id\": \"last\",\n",
    "            \"reestr_state\": \"last\",\n",
    "        }\n",
    "    )\n",
    "    features.columns = [\"_\".join(col).strip() for col in features.columns.values]\n",
    "    features = features.reset_index()\n",
    "\n",
    "    # Drop unnecessary columns from wag_param\n",
    "    m_data = wag_param.drop([\"model\", \"tipvozd\", \"date_build\", \"srok_sl\", \"date_iskl\"], axis=1)\n",
    "\n",
    "    # Merge the aggregated features with the wag_param\n",
    "    merged = features.merge(m_data, on=\"wagnum\", how=\"inner\")\n",
    "    \n",
    "    merged = merged.merge(get_dislok(), on='wagnum', how='inner')\n",
    "    \n",
    "    # If a target dataframe is provided, merge it as well\n",
    "    if target is not None:\n",
    "        merged = target.merge(merged, on=\"wagnum\", how=\"left\")\n",
    "\n",
    "    # Define and apply an imputer for missing values\n",
    "    imputer = SimpleImputer(strategy=imputer_strategy)\n",
    "\n",
    "    column_names = merged.columns\n",
    "    merged = imputer.fit_transform(merged)\n",
    "    \n",
    "    merged = pd.DataFrame(merged, columns=column_names)\n",
    "\n",
    "    if columns_to_log is not None:\n",
    "        for column in columns_to_log:\n",
    "            merged[column] = np.log(merged[column])\n",
    "\n",
    "    if columns_to_drop is not None:\n",
    "        merged = merged.drop(columns_to_drop, axis=1)\n",
    "        \n",
    "\n",
    "    \n",
    "    # Drop the 'wagnum' column to prepare the feature matrix\n",
    "    if without_wagnum:\n",
    "        merged = merged.drop([\"wagnum\"], axis=1)\n",
    "\n",
    "    return merged"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T02:49:44.716749300Z",
     "start_time": "2023-11-12T02:49:44.540094500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use most_frequent strategy with non-numeric data:\ncould not convert string to float: '2023-01-01'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 19\u001B[0m\n\u001B[0;32m      2\u001B[0m columns_to_drop \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtippogl\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      3\u001B[0m                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtormoz\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      4\u001B[0m                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnorma_km\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     14\u001B[0m                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgruz\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     15\u001B[0m                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrod_id_last\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m#columns_to_log = ['ost_prob_mean', 'ost_prob_last', 'ost_prob_max', 'tara']\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Prepare training data\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m X_train \u001B[38;5;241m=\u001B[39m \u001B[43mprepare_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwag_param\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_target\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns_to_drop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# Prepare testing data\u001B[39;00m\n\u001B[0;32m     22\u001B[0m X_test \u001B[38;5;241m=\u001B[39m prepare_data(test, wag_param, test_target, columns_to_drop)\n",
      "Cell \u001B[1;32mIn[17], line 35\u001B[0m, in \u001B[0;36mprepare_data\u001B[1;34m(group_data, wag_param, target, columns_to_drop, columns_to_drop_wag_param, columns_to_log, imputer_strategy, without_wagnum)\u001B[0m\n\u001B[0;32m     32\u001B[0m imputer \u001B[38;5;241m=\u001B[39m SimpleImputer(strategy\u001B[38;5;241m=\u001B[39mimputer_strategy)\n\u001B[0;32m     34\u001B[0m column_names \u001B[38;5;241m=\u001B[39m merged\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[1;32m---> 35\u001B[0m merged \u001B[38;5;241m=\u001B[39m \u001B[43mimputer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmerged\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m merged \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(merged, columns\u001B[38;5;241m=\u001B[39mcolumn_names)\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m columns_to_log \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\All_python_trash\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 140\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    142\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    143\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m    144\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    145\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    146\u001B[0m         )\n",
      "File \u001B[1;32mD:\\All_python_trash\\lib\\site-packages\\sklearn\\base.py:878\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    874\u001B[0m \u001B[38;5;66;03m# non-optimized default implementation; override when a better\u001B[39;00m\n\u001B[0;32m    875\u001B[0m \u001B[38;5;66;03m# method is possible for a given clustering algorithm\u001B[39;00m\n\u001B[0;32m    876\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    877\u001B[0m     \u001B[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[1;32m--> 878\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[0;32m    879\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    880\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[0;32m    881\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[1;32mD:\\All_python_trash\\lib\\site-packages\\sklearn\\impute\\_base.py:390\u001B[0m, in \u001B[0;36mSimpleImputer.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    381\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdeprecated\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    382\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    383\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mverbose\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m parameter was deprecated in version \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    384\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1.1 and will be removed in 1.3. A warning will \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    387\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    388\u001B[0m     )\n\u001B[1;32m--> 390\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_input\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43min_fit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    392\u001B[0m \u001B[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001B[39;00m\n\u001B[0;32m    393\u001B[0m \u001B[38;5;66;03m# otherwise\u001B[39;00m\n\u001B[0;32m    394\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfill_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\All_python_trash\\lib\\site-packages\\sklearn\\impute\\_base.py:342\u001B[0m, in \u001B[0;36mSimpleImputer._validate_input\u001B[1;34m(self, X, in_fit)\u001B[0m\n\u001B[0;32m    336\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcould not convert\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(ve):\n\u001B[0;32m    337\u001B[0m     new_ve \u001B[38;5;241m=\u001B[39m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    338\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot use \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m strategy with non-numeric data:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    339\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy, ve\n\u001B[0;32m    340\u001B[0m         )\n\u001B[0;32m    341\u001B[0m     )\n\u001B[1;32m--> 342\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m new_ve \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    344\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ve\n",
      "\u001B[1;31mValueError\u001B[0m: Cannot use most_frequent strategy with non-numeric data:\ncould not convert string to float: '2023-01-01'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the columns to drop from wag_param\n",
    "columns_to_drop = ['tippogl',\n",
    "                   'tormoz',\n",
    "                   'norma_km',\n",
    "                   'kuzov',\n",
    "                   'telega',\n",
    "                   'cnsi_probeg_dr',\n",
    "                   'manage_type_last',\n",
    "                   'ownertype',\n",
    "                   'cnsi_probeg_kr',\n",
    "                   'reestr_state_last', 'zavod_build',\n",
    "                   'cnsi_gruz_capacity',\n",
    "                   'rod_id',\n",
    "                   'gruz',\n",
    "                   'rod_id_last']\n",
    "\n",
    "#columns_to_log = ['ost_prob_mean', 'ost_prob_last', 'ost_prob_max', 'tara']\n",
    "# Prepare training data\n",
    "X_train = prepare_data(train, wag_param, train_target, columns_to_drop)\n",
    "\n",
    "# Prepare testing data\n",
    "X_test = prepare_data(test, wag_param, test_target, columns_to_drop)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T02:50:27.103092600Z",
     "start_time": "2023-11-12T02:49:44.553095700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T02:50:27.106095100Z",
     "start_time": "2023-11-12T02:50:27.105091500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T02:50:27.108094500Z",
     "start_time": "2023-11-12T02:50:27.107092600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.to_csv('x_train.csv', index=False)\n",
    "X_test.to_csv('x_test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T02:50:27.111092100Z",
     "start_time": "2023-11-12T02:50:27.109092Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "y_month_name = \"target_month\"\n",
    "y_day_name = \"target_day\"\n",
    "target_names = [y_month_name, y_day_name]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T02:50:27.112091700Z",
     "start_time": "2023-11-12T02:50:27.111092100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T02:50:27.134092400Z",
     "start_time": "2023-11-12T02:50:27.114091700Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training for month and day prediction\")\n",
    "\n",
    "logreg_month = LogisticRegression()\n",
    "logreg_month.fit(X_train.drop(target_names, axis=1), X_train[y_month_name])\n",
    "logreg_day = LogisticRegression()\n",
    "logreg_day.fit(X_train.drop(target_names, axis=1), X_train[y_day_name])\n",
    "\n",
    "rf_month = RandomForestClassifier()\n",
    "rf_month.fit(X_train.drop(target_names, axis=1), X_train[y_month_name])\n",
    "rf_day = RandomForestClassifier()\n",
    "rf_day.fit(X_train.drop(target_names, axis=1), X_train[y_day_name])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Подсчитаем количество примеров каждого класса\n",
    "class_counts = X_train[y_month_name].value_counts()\n",
    "# Например, если у нас два класса, то вес для каждого класса может быть обратно пропорционален его частоте.\n",
    "class_weights = class_counts.sum() / (len(class_counts) * class_counts)\n",
    "cb_month = CatBoostClassifier(random_seed=42,\n",
    "                              auto_class_weights='Balanced',\n",
    "                              #eval_metric='F1', \n",
    "                              )\n",
    "cb_month.fit(\n",
    "    X_train.drop(target_names, axis=1),\n",
    "    X_train[y_month_name],\n",
    "    eval_set=(X_test.drop(target_names, axis=1), X_test[y_month_name]),\n",
    "    verbose=False, )\n",
    "\n",
    "# Подсчитаем количество примеров каждого класса\n",
    "class_counts = X_train[y_day_name].value_counts()\n",
    "# Например, если у нас два класса, то вес для каждого класса может быть обратно пропорционален его частоте.\n",
    "class_weights = class_counts.sum() / (len(class_counts) * class_counts)\n",
    "cb_day = CatBoostClassifier(random_seed=42,\n",
    "                            auto_class_weights='Balanced',\n",
    "                            #eval_metric='F1',\n",
    "                            iterations=1000)\n",
    "cb_day.fit(\n",
    "    X_train.drop(target_names, axis=1),\n",
    "    X_train[y_day_name],\n",
    "    eval_set=(X_test.drop(target_names, axis=1), X_test[y_day_name]),\n",
    "    verbose=False,\n",
    "    use_best_model=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.116091300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.118092400Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_logreg_month = logreg_month.predict(X_test.drop(target_names, axis=1))\n",
    "y_pred_rf_month = rf_month.predict(X_test.drop(target_names, axis=1))\n",
    "y_pred_cb_month = cb_month.predict(X_test.drop(target_names, axis=1))\n",
    "\n",
    "y_pred_logreg_day = logreg_day.predict(X_test.drop(target_names, axis=1))\n",
    "y_pred_rf_day = rf_day.predict(X_test.drop(target_names, axis=1))\n",
    "y_pred_cb_day = cb_day.predict(X_test.drop(target_names, axis=1))\n",
    "\n",
    "print(\"Month score:\")\n",
    "f1_logreg_month = f1_score(X_test[y_month_name], y_pred_logreg_month)\n",
    "print(f\"Logistic Regression month F1 Score: {f1_logreg_month}\")\n",
    "f1_rf_month = f1_score(X_test[y_month_name], y_pred_rf_month)\n",
    "print(f\"Random Forest month F1 Score: {f1_rf_month}\")\n",
    "f1_cb_month = f1_score(X_test[y_month_name], y_pred_cb_month)\n",
    "print(f\"CatBoost month F1 Score: {f1_cb_month}\")\n",
    "\n",
    "print(\"Day score:\")\n",
    "f1_logreg_day = f1_score(X_test[y_day_name], y_pred_logreg_day)\n",
    "print(f\"Logistic Regression day F1 Score: {f1_logreg_day}\")\n",
    "f1_rf_day = f1_score(X_test[y_day_name], y_pred_rf_day)\n",
    "print(f\"Random Forest day F1 Score: {f1_rf_day}\")\n",
    "f1_cb_day = f1_score(X_test[y_day_name], y_pred_cb_day)\n",
    "print(f\"CatBoost day F1 Score: {f1_cb_day}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def correct_days_with_month(day_array, month_array):\n",
    "    corrected_day = day_array.copy()\n",
    "    corrected_day[month_array == 0] = 0\n",
    "    return corrected_day\n",
    "\n",
    "\n",
    "y_pred_logreg_day_corrected = correct_days_with_month(y_pred_logreg_day, y_pred_logreg_month)\n",
    "y_pred_rf_day_corrected = correct_days_with_month(y_pred_rf_day, y_pred_rf_month)\n",
    "y_pred_cb_day_corrected = correct_days_with_month(y_pred_cb_day, y_pred_cb_month)\n",
    "\n",
    "print(\"Day score after applying month info to day:\")\n",
    "f1_logreg_day = f1_score(X_test[y_day_name], y_pred_logreg_day_corrected)\n",
    "print(f\"Logistic Regression day F1 Score: {f1_logreg_day}\")\n",
    "f1_rf_day = f1_score(X_test[y_day_name], y_pred_rf_day_corrected)\n",
    "print(f\"Random Forest day F1 Score: {f1_rf_day}\")\n",
    "f1_cb_day = f1_score(X_test[y_day_name], y_pred_cb_day_corrected)\n",
    "print(f\"CatBoost day F1 Score: {f1_cb_day}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.121091100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test.drop(target_names, axis=1).columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.123093300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_importances = cb_month.get_feature_importance()\n",
    "feature_names = X_test.drop(target_names, axis=1).columns\n",
    "importance_dict = {feature_names[i]: importance for i, importance in enumerate(feature_importances)}\n",
    "sorted_f_imp = dict(sorted(importance_dict.items(), key=lambda item: item[1], reverse=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.125093800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sorted_f_imp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.128092Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(sorted_f_imp.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.133092900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wag_param.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T02:50:27.137092800Z",
     "start_time": "2023-11-12T02:50:27.136097300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.138094200Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import h2o\n",
    "# import xgboost as xgb\n",
    "# import pandas as pd\n",
    "# from h2o.automl import H2OAutoML\n",
    "# \n",
    "# h2o.init()\n",
    "# \n",
    "# model_path = \"\"\n",
    "# model_file = os.path.join(model_path, \"StackedEnsemble_AllModels_1_AutoML_2_20231111_112553\")\n",
    "# train = h2o.H2OFrame(X_train)\n",
    "# test = h2o.H2OFrame(X_test)\n",
    "# train[y_month_name] = train[y_month_name].asfactor()\n",
    "# test[y_month_name] = test[y_month_name].asfactor()\n",
    "# \n",
    "# x = train.columns\n",
    "# y = y_month_name\n",
    "# x.remove(y)\n",
    "# \n",
    "# # if os.path.exists(model_file):\n",
    "# #     print(\"sdfsd\")\n",
    "# #     aml = h2o.load_model(model_file)\n",
    "# # else:\n",
    "# aml = H2OAutoML(max_models=15, seed=42)\n",
    "# aml.train(x=x, y=y, training_frame=train)\n",
    "# \n",
    "# h2o.save_model(aml.leader, path=model_path)\n",
    "# \n",
    "# lb = aml.leaderboard\n",
    "# print(lb.head(rows=lb.nrows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T02:50:27.209907100Z",
     "start_time": "2023-11-12T02:50:27.142092100Z"
    }
   },
   "outputs": [],
   "source": [
    "# y_pred = aml.predict(test).as_data_frame().squeeze()\n",
    "# result = f1_score(X_test[y_month_name], y_pred[\"predict\"])\n",
    "# print(f\"F1: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train = h2o.H2OFrame(X_train)\n",
    "# test = h2o.H2OFrame(X_test)\n",
    "# train[y_day_name] = train[y_day_name].asfactor()\n",
    "# test[y_day_name] = test[y_day_name].asfactor()\n",
    "# x = train.columns\n",
    "# y = y_day_name\n",
    "# x.remove(y)\n",
    "# \n",
    "# # if os.path.exists(model_file):\n",
    "# #     print(\"sdfsd\")\n",
    "# #     aml = h2o.load_model(model_file)\n",
    "# # else:\n",
    "# aml_day = H2OAutoML(max_models=15, seed=42)\n",
    "# aml_day.train(x=x, y=y, training_frame=train)\n",
    "# \n",
    "# h2o.save_model(aml_day.leader, path=model_path)\n",
    "# \n",
    "# lb = aml_day.leaderboard\n",
    "# print(lb.head(rows=lb.nrows))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.146091300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# y_pred_day = aml_day.predict(test).as_data_frame().squeeze()\n",
    "# result_day = f1_score(X_test[y_day_name], y_pred_day[\"predict\"])\n",
    "# print(f\"F1: {result_day}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.150093700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Меняем train и test для того чтобы сделать корректный submission"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def prepare_data_for_submission(group_data, wag_param, target=None, columns_to_drop=None,\n",
    "#                                 columns_to_drop_wag_param=None,columns_to_log=None,\n",
    "#                                 imputer_strategy='most_frequent', without_wagnum=True):\n",
    "#     # Group and aggregate the data\n",
    "#     if columns_to_drop_wag_param is None:\n",
    "#         columns_to_drop_wag_param = [\"model\", \"tipvozd\", \"date_build\", \"srok_sl\", \"date_iskl\"]\n",
    "# \n",
    "#     features = group_data.groupby(\"wagnum\").agg(\n",
    "#         {\n",
    "#             \"ost_prob\": [\"mean\", \"last\", \"max\", 'var'],\n",
    "#             \"manage_type\": \"last\",\n",
    "#             \"rod_id\": \"last\",\n",
    "#             \"reestr_state\": \"last\",\n",
    "#         }\n",
    "#     )\n",
    "#     features.columns = [\"_\".join(col).strip() for col in features.columns.values]\n",
    "#     features = features.reset_index()\n",
    "# \n",
    "#     # Drop unnecessary columns from wag_param\n",
    "#     m_data = wag_param.drop([\"model\", \"tipvozd\", \"date_build\", \"srok_sl\", \"date_iskl\"], axis=1)\n",
    "# \n",
    "#     # Merge the aggregated features with the wag_param\n",
    "#     merged = features.merge(m_data, on=\"wagnum\", how=\"inner\")\n",
    "# \n",
    "#     # If a target dataframe is provided, merge it as well\n",
    "#     if target is not None:\n",
    "#         merged = target.merge(merged, on=\"wagnum\", how=\"left\")\n",
    "# \n",
    "#     # Define and apply an imputer for missing values\n",
    "#     imputer = SimpleImputer(strategy=imputer_strategy)\n",
    "# \n",
    "#     column_names = merged.columns\n",
    "#     merged = imputer.fit_transform(merged)\n",
    "#     merged = pd.DataFrame(merged, columns=column_names)\n",
    "#     \n",
    "#     if columns_to_log is not None:\n",
    "#         for column in columns_to_log:\n",
    "#             merged[column] = np.log(merged[column])\n",
    "# \n",
    "#     if columns_to_drop is not None:\n",
    "#         merged = merged.drop(columns_to_drop, axis=1)\n",
    "# \n",
    "#     # Drop the 'wagnum' column to prepare the feature matrix\n",
    "#     #X_data = merged.drop([\"wagnum\"], axis=1)\n",
    "# \n",
    "#     return merged"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.153083Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "wag_param_submission = pd.read_parquet(path_test + '/wag_params.parquet').convert_dtypes()\n",
    "\n",
    "wag_prob_submission = pd.read_parquet('test/wagons_probeg_ownersip.parquet').convert_dtypes()\n",
    "wag_prob_submission = pd.concat([wag_prob, wag_prob_submission])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.156080500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.159921400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_submission = prepare_data(wag_prob_submission, wag_param_submission, columns_to_drop=columns_to_drop, without_wagnum=False)\n",
    "x_submission['wagnum'] = x_submission['wagnum'].astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.162909700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_submission[['ost_prob_last', 'wagnum']].head(15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.164910Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_submission.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.167909800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission_info = pd.read_csv('train/target/y_predict.csv').convert_dtypes()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.168909700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission_info.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.169910200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission_info = submission_info.merge(x_submission, how='left', on='wagnum')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.171909500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission_info"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.172909300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# submission_h2o = h2o.H2OFrame(submission_info.drop(['wagnum', 'month'], axis=1))\n",
    "# predictions = aml.predict(submission_h2o).as_data_frame().squeeze()\n",
    "# submission_info['target_month'] = predictions['predict']\n",
    "submission_info['target_month'] = cb_month.predict(submission_info.drop(['wagnum', 'month'], axis=1)).astype(int)\n",
    "submission_info['target_day'] = cb_day.predict(submission_info.drop(['wagnum', 'month'], axis=1)).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.174908900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission_info['target_day'] = correct_days_with_month(submission_info['target_day'], submission_info['target_month'])\n",
    "submission_info.head(15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.175910200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission_info[['wagnum', 'month', 'target_month', 'target_day']].to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.176909700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.178909800Z"
    }
   },
   "outputs": [],
   "source": [
    "# h2o.save_model(aml.leader, path=f\"saved_models/h20_{result}\")\n",
    "# h2o.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.179909900Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature_importance = logreg.coef_\n",
    "# \n",
    "# avg_feature_importance = np.mean(np.abs(feature_importance), axis=0)\n",
    "# \n",
    "# feature_importance_df = pd.DataFrame(\n",
    "#     {\"Feature\": X_train.columns, \"Importance\": avg_feature_importance}\n",
    "# )\n",
    "# \n",
    "# feature_importance_df = feature_importance_df.sort_values(\n",
    "#     by=\"Importance\", ascending=False\n",
    "# )\n",
    "# \n",
    "# print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.181908800Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature_importance = rf.feature_importances_\n",
    "# \n",
    "# feature_importance_df = pd.DataFrame(\n",
    "#     {\"Feature\": X_train.columns, \"Importance\": feature_importance}\n",
    "# )\n",
    "# \n",
    "# feature_importance_df = feature_importance_df.sort_values(\n",
    "#     by=\"Importance\", ascending=False\n",
    "# )\n",
    "# \n",
    "# print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.182909Z"
    }
   },
   "outputs": [],
   "source": [
    "# import shap\n",
    "# \n",
    "# explainer = shap.TreeExplainer(rf)\n",
    "# shap_values = explainer.shap_values(X_train)\n",
    "# shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-12T02:50:27.184909400Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
